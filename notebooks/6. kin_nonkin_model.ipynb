{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Verify device availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KinshipConfig:\n",
    "    def __init__(self):\n",
    "        # Model architecture\n",
    "        self.input_size = 112  # Input image size\n",
    "        self.face_embedding_size = 512\n",
    "        \n",
    "        # Training settings\n",
    "        self.batch_size = 32\n",
    "        self.learning_rate = 1e-4\n",
    "        self.weight_decay = 5e-4\n",
    "        self.num_epochs = 10\n",
    "        \n",
    "        # Data settings\n",
    "        self.train_path = '../data/processed/fiw/train/splits/train_triplets.csv'\n",
    "        self.val_path = '../data/processed/fiw/train/splits/val_triplets.csv'\n",
    "        self.test_path = '../data/processed/fiw/train/splits/test_triplets.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Custom image processing functions\n",
    "class ImageProcessor:\n",
    "    @staticmethod\n",
    "    def read_image(path):\n",
    "        \"\"\"Read image using OpenCV and convert to RGB\"\"\"\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Could not read image: {path}\")\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    @staticmethod\n",
    "    def resize_image(img, size):\n",
    "        \"\"\"Resize image keeping aspect ratio\"\"\"\n",
    "        h, w = img.shape[:2]\n",
    "        scale = size / max(h, w)\n",
    "        new_h, new_w = int(h * scale), int(w * scale)\n",
    "        return cv2.resize(img, (new_w, new_h))\n",
    "    \n",
    "    @staticmethod\n",
    "    def pad_image(img, size):\n",
    "        \"\"\"Pad image to square\"\"\"\n",
    "        h, w = img.shape[:2]\n",
    "        pad_h = (size - h) // 2\n",
    "        pad_w = (size - w) // 2\n",
    "        return cv2.copyMakeBorder(\n",
    "            img, pad_h, pad_h, pad_w, pad_w,\n",
    "            cv2.BORDER_CONSTANT, value=[0, 0, 0]\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def preprocess_image(img):\n",
    "        \"\"\"Normalize image to [-1, 1] range\"\"\"\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img = (img - 0.5) * 2\n",
    "        return img\n",
    "    \n",
    "    @staticmethod\n",
    "    def process_face(img_path, target_size=112):\n",
    "        \"\"\"Complete face processing pipeline\"\"\"\n",
    "        try:\n",
    "            # Read image\n",
    "            img = ImageProcessor.read_image(img_path)\n",
    "            \n",
    "            # Resize keeping aspect ratio\n",
    "            img = ImageProcessor.resize_image(img, target_size)\n",
    "            \n",
    "            # Pad to square\n",
    "            img = ImageProcessor.pad_image(img, target_size)\n",
    "            \n",
    "            # Preprocess\n",
    "            img = ImageProcessor.preprocess_image(img)\n",
    "            \n",
    "            # Convert to torch tensor\n",
    "            img = torch.from_numpy(img.transpose(2, 0, 1))\n",
    "            \n",
    "            return img\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {img_path}: {str(e)}\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 4: Dataset class\n",
    "class KinshipDataset(Dataset):\n",
    "    def __init__(self, csv_path, config):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.config = config\n",
    "        self.processor = ImageProcessor()\n",
    "        \n",
    "        # Create pairs from triplets\n",
    "        self.pairs = []\n",
    "        for _, row in self.data.iterrows():\n",
    "            self.pairs.append((row['Anchor'], row['Positive'], 1))  # Kin pair\n",
    "            self.pairs.append((row['Anchor'], row['Negative'], 0))  # Non-kin pair\n",
    "        \n",
    "        print(f\"Loaded {len(self.pairs)} pairs\")\n",
    "        print(\"\\nKinship distribution:\")\n",
    "        kin_counts = pd.Series([pair[2] for pair in self.pairs]).value_counts()\n",
    "        print(kin_counts)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        anchor_path, other_path, is_related = self.pairs[idx]\n",
    "        \n",
    "        # Process images\n",
    "        anchor = self.processor.process_face(anchor_path)\n",
    "        other = self.processor.process_face(other_path)\n",
    "        \n",
    "        if anchor is None or other is None:\n",
    "            # Return a default item if processing fails\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "        \n",
    "        return {\n",
    "            'anchor': anchor,\n",
    "            'other': other,\n",
    "            'is_related': torch.tensor(is_related, dtype=torch.float)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 5: Create data loaders\n",
    "def create_dataloaders(config):\n",
    "    # Create datasets\n",
    "    train_dataset = KinshipDataset(config.train_path, config)\n",
    "    val_dataset = KinshipDataset(config.val_path, config)\n",
    "    test_dataset = KinshipDataset(config.test_path, config)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 6: Test data loading\n",
    "config = KinshipConfig()\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader, val_loader, test_loader = create_dataloaders(config)\n",
    "\n",
    "# Show dataset sizes\n",
    "print(f\"\\nTrain dataset size: {len(train_loader.dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_loader.dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_loader.dataset)}\")\n",
    "\n",
    "# Test batch loading with progress bar\n",
    "print(\"\\nLoading batches from train_loader:\")\n",
    "for batch in tqdm(train_loader, desc=\"Loading train batches\"):\n",
    "    # Just iterate to show progress\n",
    "    pass\n",
    "\n",
    "print(\"\\nLoading batches from val_loader:\")\n",
    "for batch in tqdm(val_loader, desc=\"Loading validation batches\"):\n",
    "    # Just iterate to show progress\n",
    "    pass\n",
    "\n",
    "print(\"\\nLoading batches from test_loader:\")\n",
    "for batch in tqdm(test_loader, desc=\"Loading test batches\"):\n",
    "    # Just iterate to show progress\n",
    "    pass\n",
    "\n",
    "# Test batch loading\n",
    "batch = next(iter(train_loader))\n",
    "print(\"\\nBatch contents:\")\n",
    "for k, v in batch.items():\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        print(f\"{k}: shape {v.shape}, dtype {v.dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 7: Model components - Blocks\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\"Squeeze-and-Excitation Block\"\"\"\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual Block with SE attention\"\"\"\n",
    "    def __init__(self, in_c, out_c, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_c)\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_c)\n",
    "        self.se = SEBlock(out_c)\n",
    "        self.downsample = downsample\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.se(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 8: Feature Extractor Network\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initial convolution\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Residual layers\n",
    "        self.layer1 = self._make_layer(64, 64, 3)\n",
    "        self.layer2 = self._make_layer(64, 128, 4, stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, 6, stride=2)\n",
    "        self.layer4 = self._make_layer(256, 512, 3, stride=2)\n",
    "        \n",
    "        # Final layers\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, config.face_embedding_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def _make_layer(self, in_c, out_c, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or in_c != out_c:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_c, out_c, 1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_c),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(in_c, out_c, stride, downsample))\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(ResidualBlock(out_c, out_c))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return F.normalize(x, p=2, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 9: Kinship Verification Model\n",
    "class KinshipModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # Feature extractor (shared weights)\n",
    "        self.feature_extractor = FeatureExtractor(config)\n",
    "        \n",
    "        # Fusion layers\n",
    "        fusion_size = config.face_embedding_size * 2\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(fusion_size, fusion_size // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(fusion_size // 2, fusion_size // 4),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Kinship verification head\n",
    "        hidden_size = fusion_size // 4\n",
    "        self.kinship_verifier = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, anchor, other):\n",
    "        # Extract features\n",
    "        anchor_features = self.feature_extractor(anchor)\n",
    "        other_features = self.feature_extractor(other)\n",
    "        \n",
    "        # Concatenate features\n",
    "        pair_features = torch.cat([anchor_features, other_features], dim=1)\n",
    "        \n",
    "        # Fuse features\n",
    "        fused_features = self.fusion(pair_features)\n",
    "        \n",
    "        # Get kinship score\n",
    "        kinship_score = self.kinship_verifier(fused_features)\n",
    "        \n",
    "        return {\n",
    "            'kinship_score': kinship_score.squeeze(),\n",
    "            'anchor_features': anchor_features,\n",
    "            'other_features': other_features\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 10: Loss functions\n",
    "class KinshipLoss:\n",
    "    def __init__(self, config):\n",
    "        self.bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def compute_loss(self, predictions, targets):\n",
    "        # Kinship verification loss\n",
    "        kinship_loss = self.bce_loss(\n",
    "            predictions['kinship_score'],\n",
    "            targets['is_related']\n",
    "        )\n",
    "        \n",
    "        return kinship_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 11: Training functions\n",
    "def train_epoch(model, train_loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc='Training')\n",
    "    for batch in progress_bar:\n",
    "        # Move data to device\n",
    "        anchor = batch['anchor'].to(device)\n",
    "        other = batch['other'].to(device)\n",
    "        is_related = batch['is_related'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        predictions = model(anchor, other)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn.compute_loss(predictions, {'is_related': is_related})\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update metrics\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate(model, val_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc='Validation'):\n",
    "            # Move data to device\n",
    "            anchor = batch['anchor'].to(device)\n",
    "            other = batch['other'].to(device)\n",
    "            is_related = batch['is_related'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            predictions = model(anchor, other)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = loss_fn.compute_loss(predictions, {'is_related': is_related})\n",
    "            \n",
    "            # Update metrics\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 12: Training loop\n",
    "def train_model(model, train_loader, val_loader, config):\n",
    "    # Setup\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config.learning_rate,\n",
    "        weight_decay=config.weight_decay\n",
    "    )\n",
    "    \n",
    "    loss_fn = KinshipLoss(config)\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(config.num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{config.num_epochs}\")\n",
    "        \n",
    "        # Train\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss = validate(model, val_loader, loss_fn, device)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "            }, 'best_kin_nonkin_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 13: Main training script\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize config\n",
    "    config = KinshipConfig()\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader, val_loader, test_loader = create_dataloaders(config)\n",
    "    \n",
    "    # Create model\n",
    "    model = KinshipModel(config).to(device)\n",
    "    \n",
    "    # Train model\n",
    "    train_model(model, train_loader, val_loader, config)\n",
    "    \n",
    "    print(\"Training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, accuracy_score\n",
    "\n",
    "def evaluate_model(model, test_loader, config):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc='Testing'):\n",
    "            # Move data to device\n",
    "            anchor = batch['anchor'].to(device)\n",
    "            other = batch['other'].to(device)\n",
    "            is_related = batch['is_related'].to(device)\n",
    "            \n",
    "            # Get predictions\n",
    "            outputs = model(anchor, other)\n",
    "            kinship_score = outputs['kinship_score']\n",
    "            \n",
    "            # Convert logits to probabilities\n",
    "            kinship_prob = torch.sigmoid(kinship_score)\n",
    "            \n",
    "            # Store results\n",
    "            probabilities.extend(kinship_prob.cpu().numpy())\n",
    "            predictions.extend((kinship_prob > 0.5).cpu().numpy())\n",
    "            labels.extend(is_related.cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    probabilities = np.array(probabilities)\n",
    "    predictions = np.array(predictions)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "    roc_auc = roc_auc_score(labels, probabilities)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "    # Evaluate based on sureness rate\n",
    "    thresholds = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    for threshold in thresholds:\n",
    "        sure_predictions = (probabilities > threshold).astype(int)\n",
    "        sure_accuracy = accuracy_score(labels, sure_predictions)\n",
    "        sure_precision, sure_recall, sure_f1, _ = precision_recall_fscore_support(labels, sure_predictions, average='binary')\n",
    "        print(f\"\\nThreshold: {threshold}\")\n",
    "        print(f\"Accuracy: {sure_accuracy:.4f}\")\n",
    "        print(f\"Precision: {sure_precision:.4f}\")\n",
    "        print(f\"Recall: {sure_recall:.4f}\")\n",
    "        print(f\"F1 Score: {sure_f1:.4f}\")\n",
    "    \n",
    "    return probabilities, labels\n",
    "\n",
    "# Cell 15: Run evaluation\n",
    "if __name__ == \"__main__\":\n",
    "    # Load best model\n",
    "    checkpoint = torch.load('best_kin_nonkin_model.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Evaluate model\n",
    "    probabilities, labels = evaluate_model(model, test_loader, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kinship_recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
